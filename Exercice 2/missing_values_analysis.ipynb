{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47215ad9",
   "metadata": {},
   "source": [
    "# Exercice 2 : Identification et Traitement des Valeurs Manquantes\n",
    "\n",
    "## Objectifs\n",
    "- Identifier les valeurs manquantes dans différents types de datasets\n",
    "- Explorer les patterns de valeurs manquantes\n",
    "- Implémenter différentes stratégies de traitement\n",
    "- Comparer l'impact des stratégies sur les performances\n",
    "\n",
    "## Stratégies couvertes\n",
    "1. **Suppression** : Lignes et colonnes\n",
    "2. **Imputation simple** : Moyenne, médiane, mode\n",
    "3. **Imputation avancée** : KNN, itérative (MICE)\n",
    "4. **Analyse d'impact** : Comparaison des performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab54e33",
   "metadata": {},
   "source": [
    "## 1. Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82af7308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration pour un meilleur affichage\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✅ Librairies importées avec succès!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038e56fc",
   "metadata": {},
   "source": [
    "## 2. Création d'un dataset avec valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd08fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_dataset():\n",
    "    \"\"\"Crée un dataset d'exemple avec différents types de valeurs manquantes\"\"\"\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    # Créer les données de base\n",
    "    data = {\n",
    "        'age': np.random.randint(18, 80, n_samples),\n",
    "        'income': np.random.normal(50000, 15000, n_samples),\n",
    "        'education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], n_samples),\n",
    "        'experience': np.random.randint(0, 40, n_samples),\n",
    "        'city': np.random.choice(['Paris', 'Lyon', 'Marseille', 'Toulouse', 'Nice'], n_samples),\n",
    "        'satisfaction': np.random.randint(1, 6, n_samples),\n",
    "        'target': np.random.choice(['Classe_A', 'Classe_B', 'Classe_C'], n_samples)\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Introduire différents types de valeurs manquantes\n",
    "    \n",
    "    # 1. MCAR (Missing Completely At Random) - Age\n",
    "    mcar_indices = np.random.choice(df.index, size=int(0.05 * len(df)), replace=False)\n",
    "    df.loc[mcar_indices, 'age'] = np.nan\n",
    "    \n",
    "    # 2. MAR (Missing At Random) - Income manquant pour les jeunes\n",
    "    young_indices = df[df['age'] < 25].index\n",
    "    mar_indices = np.random.choice(young_indices, size=int(0.3 * len(young_indices)), replace=False)\n",
    "    df.loc[mar_indices, 'income'] = np.nan\n",
    "    \n",
    "    # 3. MNAR (Missing Not At Random) - Education manquante pour satisfaction faible\n",
    "    low_satisfaction = df[df['satisfaction'] <= 2].index\n",
    "    mnar_indices = np.random.choice(low_satisfaction, size=int(0.4 * len(low_satisfaction)), replace=False)\n",
    "    df.loc[mnar_indices, 'education'] = np.nan\n",
    "    \n",
    "    # 4. Valeurs manquantes additionnelles\n",
    "    df.loc[np.random.choice(df.index, 50, replace=False), 'experience'] = np.nan\n",
    "    df.loc[np.random.choice(df.index, 30, replace=False), 'city'] = np.nan\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Créer le dataset\n",
    "df = create_sample_dataset()\n",
    "print(f\"Dataset créé: {df.shape}\")\n",
    "print(f\"Valeurs manquantes totales: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Afficher les premières lignes\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663adc59",
   "metadata": {},
   "source": [
    "## 3. Analyse exploratoire des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b568ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques générales\n",
    "total_cells = np.product(df.shape)\n",
    "total_missing = df.isnull().sum().sum()\n",
    "missing_percentage = (total_missing / total_cells) * 100\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ANALYSE DES VALEURS MANQUANTES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Dimensions du dataset: {df.shape}\")\n",
    "print(f\"Total de cellules: {total_cells:,}\")\n",
    "print(f\"Total de valeurs manquantes: {total_missing:,}\")\n",
    "print(f\"Pourcentage global: {missing_percentage:.2f}%\")\n",
    "\n",
    "# Statistiques par colonne\n",
    "missing_by_column = df.isnull().sum()\n",
    "missing_percentage_by_column = (missing_by_column / len(df)) * 100\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Valeurs_Manquantes': missing_by_column,\n",
    "    'Pourcentage': missing_percentage_by_column\n",
    "}).sort_values('Valeurs_Manquantes', ascending=False)\n",
    "\n",
    "print(\"\\nValeurs manquantes par colonne:\")\n",
    "print(missing_summary[missing_summary['Valeurs_Manquantes'] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd6d18e",
   "metadata": {},
   "source": [
    "## 4. Visualisation des patterns de valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f3cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer les visualisations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Analyse des Valeurs Manquantes', fontsize=16)\n",
    "\n",
    "# 1. Heatmap des valeurs manquantes\n",
    "missing_data = df.isnull()\n",
    "sns.heatmap(missing_data, yticklabels=False, cbar=True, cmap='viridis', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Heatmap des Valeurs Manquantes')\n",
    "\n",
    "# 2. Barplot des valeurs manquantes par colonne\n",
    "missing_counts = df.isnull().sum()\n",
    "missing_counts = missing_counts[missing_counts > 0].sort_values(ascending=True)\n",
    "missing_counts.plot(kind='barh', ax=axes[0, 1], color='coral')\n",
    "axes[0, 1].set_title('Nombre de Valeurs Manquantes par Colonne')\n",
    "axes[0, 1].set_xlabel('Nombre de valeurs manquantes')\n",
    "\n",
    "# 3. Matrice de corrélation des patterns manquants\n",
    "missing_corr = missing_data.corr()\n",
    "sns.heatmap(missing_corr, annot=True, cmap='coolwarm', center=0, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Corrélation des Patterns Manquants')\n",
    "\n",
    "# 4. Distribution des valeurs manquantes par ligne\n",
    "missing_per_row = missing_data.sum(axis=1)\n",
    "missing_per_row.hist(bins=20, ax=axes[1, 1], color='skyblue')\n",
    "axes[1, 1].set_title('Distribution des Valeurs Manquantes par Ligne')\n",
    "axes[1, 1].set_xlabel('Nombre de valeurs manquantes par ligne')\n",
    "axes[1, 1].set_ylabel('Fréquence')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4f9dd4",
   "metadata": {},
   "source": [
    "## 5. Stratégie 1 : Suppression des lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bc786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STRATÉGIE 1: SUPPRESSION DES LIGNES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Option A: Supprimer toutes les lignes avec des valeurs manquantes\n",
    "df_drop_any = df.dropna()\n",
    "print(f\"Suppression de toutes les lignes avec valeurs manquantes:\")\n",
    "print(f\"  Forme originale: {df.shape}\")\n",
    "print(f\"  Forme après suppression: {df_drop_any.shape}\")\n",
    "print(f\"  Lignes supprimées: {df.shape[0] - df_drop_any.shape[0]}\")\n",
    "print(f\"  Pourcentage conservé: {(len(df_drop_any)/len(df))*100:.1f}%\")\n",
    "\n",
    "# Option B: Supprimer seulement les lignes avec plus de X valeurs manquantes\n",
    "threshold = 2  # Supprimer si plus de 2 valeurs manquantes\n",
    "df_drop_thresh = df.dropna(thresh=len(df.columns) - threshold)\n",
    "print(f\"\\nSuppression des lignes avec plus de {threshold} valeurs manquantes:\")\n",
    "print(f\"  Forme après suppression: {df_drop_thresh.shape}\")\n",
    "print(f\"  Lignes supprimées: {df.shape[0] - df_drop_thresh.shape[0]}\")\n",
    "print(f\"  Pourcentage conservé: {(len(df_drop_thresh)/len(df))*100:.1f}%\")\n",
    "\n",
    "# Vérifier les valeurs manquantes restantes\n",
    "print(f\"\\nValeurs manquantes restantes (dropna): {df_drop_any.isnull().sum().sum()}\")\n",
    "print(f\"Valeurs manquantes restantes (thresh): {df_drop_thresh.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143f53dd",
   "metadata": {},
   "source": [
    "## 6. Stratégie 2 : Suppression des colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ffd341",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STRATÉGIE 2: SUPPRESSION DES COLONNES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Définir le seuil de suppression (ex: 30% de valeurs manquantes)\n",
    "threshold = 0.3\n",
    "\n",
    "# Calculer le pourcentage de valeurs manquantes par colonne\n",
    "missing_percentage = df.isnull().sum() / len(df)\n",
    "columns_to_drop = missing_percentage[missing_percentage > threshold].index\n",
    "\n",
    "print(f\"Seuil de suppression: {threshold*100:.0f}% de valeurs manquantes\")\n",
    "print(f\"Colonnes à supprimer: {list(columns_to_drop)}\")\n",
    "\n",
    "# Supprimer les colonnes\n",
    "df_drop_cols = df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"\\nForme originale: {df.shape}\")\n",
    "print(f\"Forme après suppression: {df_drop_cols.shape}\")\n",
    "print(f\"Colonnes conservées: {df_drop_cols.shape[1]}/{df.shape[1]}\")\n",
    "\n",
    "# Afficher les valeurs manquantes restantes\n",
    "remaining_missing = df_drop_cols.isnull().sum()\n",
    "print(f\"\\nValeurs manquantes restantes par colonne:\")\n",
    "print(remaining_missing[remaining_missing > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830e1694",
   "metadata": {},
   "source": [
    "## 7. Stratégie 3 : Imputation simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf9773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STRATÉGIE 3: IMPUTATION SIMPLE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Préparer les données\n",
    "df_impute_simple = df.copy()\n",
    "\n",
    "# Séparer les colonnes par type\n",
    "numeric_cols = df_impute_simple.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = df_impute_simple.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(f\"Colonnes numériques: {list(numeric_cols)}\")\n",
    "print(f\"Colonnes catégorielles: {list(categorical_cols)}\")\n",
    "\n",
    "# Imputation pour les colonnes numériques (moyenne)\n",
    "if len(numeric_cols) > 0:\n",
    "    imputer_numeric = SimpleImputer(strategy='mean')\n",
    "    df_impute_simple[numeric_cols] = imputer_numeric.fit_transform(df_impute_simple[numeric_cols])\n",
    "    print(f\"\\n✅ Imputation par moyenne appliquée aux colonnes numériques\")\n",
    "\n",
    "# Imputation pour les colonnes catégorielles (mode)\n",
    "if len(categorical_cols) > 0:\n",
    "    for col in categorical_cols:\n",
    "        if df_impute_simple[col].isnull().any():\n",
    "            mode_value = df_impute_simple[col].mode()[0] if not df_impute_simple[col].mode().empty else 'Unknown'\n",
    "            df_impute_simple[col].fillna(mode_value, inplace=True)\n",
    "    print(f\"✅ Imputation par mode appliquée aux colonnes catégorielles\")\n",
    "\n",
    "# Vérification\n",
    "remaining_missing = df_impute_simple.isnull().sum().sum()\n",
    "print(f\"\\nValeurs manquantes restantes: {remaining_missing}\")\n",
    "print(f\"Forme du dataset: {df_impute_simple.shape}\")\n",
    "\n",
    "# Comparaison des statistiques avant/après\n",
    "print(\"\\nComparaison des moyennes (colonnes numériques):\")\n",
    "for col in numeric_cols:\n",
    "    original_mean = df[col].mean()\n",
    "    imputed_mean = df_impute_simple[col].mean()\n",
    "    print(f\"  {col}: {original_mean:.2f} → {imputed_mean:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76abc4c7",
   "metadata": {},
   "source": [
    "## 8. Stratégie 4 : Imputation par médiane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d1b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STRATÉGIE 4: IMPUTATION PAR MÉDIANE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Préparer les données\n",
    "df_impute_median = df.copy()\n",
    "\n",
    "# Imputation par médiane pour les colonnes numériques\n",
    "if len(numeric_cols) > 0:\n",
    "    imputer_median = SimpleImputer(strategy='median')\n",
    "    df_impute_median[numeric_cols] = imputer_median.fit_transform(df_impute_median[numeric_cols])\n",
    "    print(f\"✅ Imputation par médiane appliquée aux colonnes numériques\")\n",
    "\n",
    "# Imputation par mode pour les colonnes catégorielles\n",
    "if len(categorical_cols) > 0:\n",
    "    for col in categorical_cols:\n",
    "        if df_impute_median[col].isnull().any():\n",
    "            mode_value = df_impute_median[col].mode()[0] if not df_impute_median[col].mode().empty else 'Unknown'\n",
    "            df_impute_median[col].fillna(mode_value, inplace=True)\n",
    "    print(f\"✅ Imputation par mode appliquée aux colonnes catégorielles\")\n",
    "\n",
    "# Vérification\n",
    "print(f\"\\nValeurs manquantes restantes: {df_impute_median.isnull().sum().sum()}\")\n",
    "\n",
    "# Comparaison moyenne vs médiane\n",
    "print(\"\\nComparaison Moyenne vs Médiane:\")\n",
    "for col in numeric_cols:\n",
    "    original_median = df[col].median()\n",
    "    mean_imputed = df_impute_simple[col].median()\n",
    "    median_imputed = df_impute_median[col].median()\n",
    "    print(f\"  {col}:\")\n",
    "    print(f\"    Original: {original_median:.2f}\")\n",
    "    print(f\"    Après imputation moyenne: {mean_imputed:.2f}\")\n",
    "    print(f\"    Après imputation médiane: {median_imputed:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2b2e32",
   "metadata": {},
   "source": [
    "## 9. Stratégie 5 : Imputation KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22331d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STRATÉGIE 5: IMPUTATION KNN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Préparer les données pour KNN (encoder les variables catégorielles)\n",
    "df_for_knn = df.copy()\n",
    "label_encoders = {}\n",
    "\n",
    "# Encoder les variables catégorielles\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    # Gérer les valeurs manquantes en les remplaçant temporairement\n",
    "    mask = df_for_knn[col].notna()\n",
    "    if mask.sum() > 0:  # Si il y a des valeurs non-manquantes\n",
    "        df_for_knn.loc[mask, col] = le.fit_transform(df_for_knn.loc[mask, col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Convertir tout en numérique\n",
    "df_numeric = df_for_knn.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Appliquer l'imputation KNN\n",
    "k_neighbors = 5\n",
    "imputer_knn = KNNImputer(n_neighbors=k_neighbors)\n",
    "df_imputed_knn = imputer_knn.fit_transform(df_numeric)\n",
    "\n",
    "# Créer le DataFrame résultat\n",
    "df_impute_knn = pd.DataFrame(df_imputed_knn, columns=df.columns, index=df.index)\n",
    "\n",
    "# Décoder les variables catégorielles\n",
    "for col, le in label_encoders.items():\n",
    "    # Arrondir et convertir en entier pour le décodage\n",
    "    encoded_values = df_impute_knn[col].round().astype(int)\n",
    "    # S'assurer que les valeurs sont dans la plage valide\n",
    "    encoded_values = np.clip(encoded_values, 0, len(le.classes_) - 1)\n",
    "    df_impute_knn[col] = le.inverse_transform(encoded_values)\n",
    "\n",
    "print(f\"✅ Imputation KNN avec k={k_neighbors} appliquée\")\n",
    "print(f\"Valeurs manquantes restantes: {df_impute_knn.isnull().sum().sum()}\")\n",
    "print(f\"Forme du dataset: {df_impute_knn.shape}\")\n",
    "\n",
    "# Afficher quelques statistiques\n",
    "print(\"\\nComparaison des moyennes (avant/après KNN):\")\n",
    "for col in numeric_cols:\n",
    "    original_mean = df[col].mean()\n",
    "    knn_mean = df_impute_knn[col].mean()\n",
    "    print(f\"  {col}: {original_mean:.2f} → {knn_mean:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5499dbcf",
   "metadata": {},
   "source": [
    "## 10. Stratégie 6 : Imputation itérative (MICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa91562",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STRATÉGIE 6: IMPUTATION ITÉRATIVE (MICE)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Préparer les données (même processus que pour KNN)\n",
    "df_for_mice = df.copy()\n",
    "mice_encoders = {}\n",
    "\n",
    "# Encoder les variables catégorielles\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    mask = df_for_mice[col].notna()\n",
    "    if mask.sum() > 0:\n",
    "        df_for_mice.loc[mask, col] = le.fit_transform(df_for_mice.loc[mask, col])\n",
    "        mice_encoders[col] = le\n",
    "\n",
    "# Convertir en numérique\n",
    "df_numeric_mice = df_for_mice.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Appliquer l'imputation itérative\n",
    "max_iter = 10\n",
    "imputer_mice = IterativeImputer(max_iter=max_iter, random_state=42)\n",
    "df_imputed_mice = imputer_mice.fit_transform(df_numeric_mice)\n",
    "\n",
    "# Créer le DataFrame résultat\n",
    "df_impute_mice = pd.DataFrame(df_imputed_mice, columns=df.columns, index=df.index)\n",
    "\n",
    "# Décoder les variables catégorielles\n",
    "for col, le in mice_encoders.items():\n",
    "    encoded_values = df_impute_mice[col].round().astype(int)\n",
    "    encoded_values = np.clip(encoded_values, 0, len(le.classes_) - 1)\n",
    "    df_impute_mice[col] = le.inverse_transform(encoded_values)\n",
    "\n",
    "print(f\"✅ Imputation MICE avec max_iter={max_iter} appliquée\")\n",
    "print(f\"Nombre d'itérations utilisées: {imputer_mice.n_iter_}\")\n",
    "print(f\"Valeurs manquantes restantes: {df_impute_mice.isnull().sum().sum()}\")\n",
    "\n",
    "# Comparaison des moyennes\n",
    "print(\"\\nComparaison des moyennes (avant/après MICE):\")\n",
    "for col in numeric_cols:\n",
    "    original_mean = df[col].mean()\n",
    "    mice_mean = df_impute_mice[col].mean()\n",
    "    print(f\"  {col}: {original_mean:.2f} → {mice_mean:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0180d44",
   "metadata": {},
   "source": [
    "## 11. Comparaison de toutes les stratégies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba4fb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regrouper tous les résultats\n",
    "strategies_results = {\n",
    "    'Original': df,\n",
    "    'Suppression_Lignes': df_drop_any,\n",
    "    'Suppression_Colonnes': df_drop_cols,\n",
    "    'Imputation_Moyenne': df_impute_simple,\n",
    "    'Imputation_Médiane': df_impute_median,\n",
    "    'Imputation_KNN': df_impute_knn,\n",
    "    'Imputation_MICE': df_impute_mice\n",
    "}\n",
    "\n",
    "# Créer un résumé comparatif\n",
    "comparison_data = []\n",
    "\n",
    "for strategy_name, data in strategies_results.items():\n",
    "    if data is not None and len(data) > 0:\n",
    "        comparison_data.append({\n",
    "            'Stratégie': strategy_name,\n",
    "            'Nb_Observations': len(data),\n",
    "            'Nb_Features': len(data.columns),\n",
    "            'Valeurs_Manquantes': data.isnull().sum().sum(),\n",
    "            'Pourcentage_Données_Conservées': (len(data) / len(df)) * 100,\n",
    "            'Pourcentage_Features_Conservées': (len(data.columns) / len(df.columns)) * 100\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPARAISON DE TOUTES LES STRATÉGIES\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5a9b9b",
   "metadata": {},
   "source": [
    "## 12. Visualisation de la comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78feb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer des visualisations comparatives\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "fig.suptitle('Comparaison des Stratégies de Traitement', fontsize=16)\n",
    "\n",
    "# 1. Nombre d'observations conservées\n",
    "comparison_df.plot(x='Stratégie', y='Nb_Observations', kind='bar', ax=axes[0, 0], color='skyblue')\n",
    "axes[0, 0].set_title('Nombre d\\'Observations Conservées')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Pourcentage de données conservées\n",
    "comparison_df.plot(x='Stratégie', y='Pourcentage_Données_Conservées', kind='bar', ax=axes[0, 1], color='lightgreen')\n",
    "axes[0, 1].set_title('Pourcentage de Données Conservées')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "axes[0, 1].set_ylabel('Pourcentage (%)')\n",
    "\n",
    "# 3. Valeurs manquantes restantes\n",
    "comparison_df.plot(x='Stratégie', y='Valeurs_Manquantes', kind='bar', ax=axes[0, 2], color='coral')\n",
    "axes[0, 2].set_title('Valeurs Manquantes Restantes')\n",
    "axes[0, 2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Comparaison des moyennes pour une variable numérique\n",
    "income_means = []\n",
    "strategy_names = []\n",
    "for name, data in strategies_results.items():\n",
    "    if data is not None and 'income' in data.columns and len(data) > 0:\n",
    "        income_means.append(data['income'].mean())\n",
    "        strategy_names.append(name)\n",
    "\n",
    "axes[1, 0].bar(strategy_names, income_means, color='gold')\n",
    "axes[1, 0].set_title('Moyenne des Revenus par Stratégie')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "axes[1, 0].set_ylabel('Revenu moyen')\n",
    "\n",
    "# 5. Distribution de l'âge pour quelques stratégies\n",
    "strategies_to_plot = ['Original', 'Imputation_Moyenne', 'Imputation_KNN', 'Imputation_MICE']\n",
    "for i, strategy in enumerate(strategies_to_plot):\n",
    "    if strategy in strategies_results and 'age' in strategies_results[strategy].columns:\n",
    "        axes[1, 1].hist(strategies_results[strategy]['age'].dropna(), alpha=0.5, label=strategy, bins=20)\n",
    "axes[1, 1].set_title('Distribution de l\\'Âge par Stratégie')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].set_xlabel('Âge')\n",
    "axes[1, 1].set_ylabel('Fréquence')\n",
    "\n",
    "# 6. Boxplot des revenus par stratégie\n",
    "income_data_for_box = []\n",
    "labels_for_box = []\n",
    "for name in ['Original', 'Imputation_Moyenne', 'Imputation_Médiane', 'Imputation_KNN']:\n",
    "    if name in strategies_results and 'income' in strategies_results[name].columns:\n",
    "        income_data_for_box.append(strategies_results[name]['income'].dropna())\n",
    "        labels_for_box.append(name)\n",
    "\n",
    "if income_data_for_box:\n",
    "    axes[1, 2].boxplot(income_data_for_box, labels=labels_for_box)\n",
    "    axes[1, 2].set_title('Distribution des Revenus par Stratégie')\n",
    "    axes[1, 2].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 2].set_ylabel('Revenu')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72be516d",
   "metadata": {},
   "source": [
    "## 13. Évaluation de l'impact sur un modèle de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8819c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ÉVALUATION DE L'IMPACT SUR UN MODÈLE DE CLASSIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "model_results = []\n",
    "\n",
    "# Tester chaque stratégie avec un modèle de classification\n",
    "for strategy_name, data in strategies_results.items():\n",
    "    if data is None or len(data) == 0 or 'target' not in data.columns:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Préparer les données\n",
    "        X = data.drop(columns=['target'])\n",
    "        y = data['target']\n",
    "        \n",
    "        # Vérifier s'il y a encore des valeurs manquantes\n",
    "        if X.isnull().sum().sum() > 0:\n",
    "            print(f\"⚠️  {strategy_name}: Contient encore des valeurs manquantes, ignoré\")\n",
    "            continue\n",
    "        \n",
    "        # Encoder les variables catégorielles\n",
    "        X_encoded = X.copy()\n",
    "        encoders = {}\n",
    "        for col in X_encoded.select_dtypes(include=['object']).columns:\n",
    "            le = LabelEncoder()\n",
    "            X_encoded[col] = le.fit_transform(X_encoded[col])\n",
    "            encoders[col] = le\n",
    "        \n",
    "        # Encoder la variable cible\n",
    "        le_target = LabelEncoder()\n",
    "        y_encoded = le_target.fit_transform(y)\n",
    "        \n",
    "        # Vérifier qu'il y a assez de données pour faire un split\n",
    "        if len(X_encoded) < 10:\n",
    "            print(f\"⚠️  {strategy_name}: Pas assez de données ({len(X_encoded)} observations)\")\n",
    "            continue\n",
    "        \n",
    "        # Diviser les données\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_encoded, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "        )\n",
    "        \n",
    "        # Entraîner le modèle\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Prédictions et évaluation\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        model_results.append({\n",
    "            'Stratégie': strategy_name,\n",
    "            'Accuracy': accuracy,\n",
    "            'Taille_Train': len(X_train),\n",
    "            'Taille_Test': len(X_test),\n",
    "            'Nb_Features': len(X.columns)\n",
    "        })\n",
    "        \n",
    "        print(f\"✅ {strategy_name}: Accuracy = {accuracy:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur avec {strategy_name}: {e}\")\n",
    "\n",
    "# Afficher les résultats\n",
    "if model_results:\n",
    "    model_results_df = pd.DataFrame(model_results)\n",
    "    print(\"\\nRésultats de performance des modèles:\")\n",
    "    print(model_results_df.round(4))\n",
    "    \n",
    "    # Visualiser les performances\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    model_results_df.plot(x='Stratégie', y='Accuracy', kind='bar', ax=plt.gca(), color='lightblue')\n",
    "    plt.title('Performance des Modèles par Stratégie')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(model_results_df['Taille_Train'], model_results_df['Accuracy'], s=100, alpha=0.7)\n",
    "    for i, row in model_results_df.iterrows():\n",
    "        plt.annotate(row['Stratégie'], (row['Taille_Train'], row['Accuracy']), \n",
    "                    xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "    plt.xlabel('Taille du Set d\\'Entraînement')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy vs Taille des Données')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Aucun résultat de modèle disponible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9358f4",
   "metadata": {},
   "source": [
    "## 14. Recommandations et conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d7c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"RECOMMANDATIONS ET CONCLUSIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n🎯 CHOIX DE LA STRATÉGIE EN FONCTION DU CONTEXTE:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"1. SUPPRESSION DES LIGNES:\")\n",
    "print(\"   ✅ Quand: <5% de valeurs manquantes et MCAR (Missing Completely At Random)\")\n",
    "print(\"   ✅ Avantage: Simple, pas de biais d'imputation\")\n",
    "print(\"   ❌ Inconvénient: Perte de données, réduction de la puissance statistique\")\n",
    "\n",
    "print(\"\\n2. SUPPRESSION DES COLONNES:\")\n",
    "print(\"   ✅ Quand: >50% de valeurs manquantes dans une colonne\")\n",
    "print(\"   ✅ Avantage: Élimine les variables peu fiables\")\n",
    "print(\"   ❌ Inconvénient: Perte d'information potentiellement utile\")\n",
    "\n",
    "print(\"\\n3. IMPUTATION SIMPLE (Moyenne/Médiane/Mode):\")\n",
    "print(\"   ✅ Quand: Données MCAR avec distribution normale\")\n",
    "print(\"   ✅ Avantage: Rapide, facile à implémenter\")\n",
    "print(\"   ❌ Inconvénient: Réduit la variance, peut introduire des biais\")\n",
    "\n",
    "print(\"\\n4. IMPUTATION KNN:\")\n",
    "print(\"   ✅ Quand: Relations locales importantes entre observations\")\n",
    "print(\"   ✅ Avantage: Préserve les patterns locaux\")\n",
    "print(\"   ❌ Inconvénient: Sensible aux outliers, computationnellement coûteux\")\n",
    "\n",
    "print(\"\\n5. IMPUTATION ITÉRATIVE (MICE):\")\n",
    "print(\"   ✅ Quand: Relations complexes entre variables\")\n",
    "print(\"   ✅ Avantage: Modélise les interdépendances\")\n",
    "print(\"   ❌ Inconvénient: Plus complexe, peut ne pas converger\")\n",
    "\n",
    "print(\"\\n\\n📊 FACTEURS À CONSIDÉRER:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"• Type de mécanisme de manquance:\")\n",
    "print(\"  - MCAR: Missing Completely At Random\")\n",
    "print(\"  - MAR: Missing At Random\")\n",
    "print(\"  - MNAR: Missing Not At Random\")\n",
    "print(\"\\n• Proportion de valeurs manquantes\")\n",
    "print(\"• Taille du dataset\")\n",
    "print(\"• Nature des variables (numériques vs catégorielles)\")\n",
    "print(\"• Objectif de l'analyse (exploration vs prédiction)\")\n",
    "print(\"• Contraintes computationnelles\")\n",
    "\n",
    "print(\"\\n\\n🏆 RECOMMANDATIONS GÉNÉRALES:\")\n",
    "print(\"-\" * 35)\n",
    "print(\"1. Toujours analyser le pattern des valeurs manquantes AVANT de choisir une stratégie\")\n",
    "print(\"2. Tester plusieurs stratégies et comparer leurs impacts\")\n",
    "print(\"3. Documenter la stratégie choisie et ses justifications\")\n",
    "print(\"4. Considérer l'impact sur les analyses en aval\")\n",
    "print(\"5. Prévoir une validation croisée robuste\")\n",
    "\n",
    "print(\"\\n✅ Exercice 2 terminé avec succès!\")\n",
    "print(\"📈 Vous maîtrisez maintenant les principales stratégies de traitement des valeurs manquantes.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
